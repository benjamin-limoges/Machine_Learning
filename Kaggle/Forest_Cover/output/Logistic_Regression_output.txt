# Tuning hyper-parameters for precision

Best parameters set found on training set:

LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, penalty='l1', random_state=None, tol=0.0001)
Grid scores on training set:
0.553 (+/-0.005) for {'penalty': 'l1', 'C': 0.001}
0.599 (+/-0.008) for {'penalty': 'l2', 'C': 0.001}
0.604 (+/-0.007) for {'penalty': 'l1', 'C': 0.01}
0.636 (+/-0.004) for {'penalty': 'l2', 'C': 0.01}
0.657 (+/-0.003) for {'penalty': 'l1', 'C': 0.1}
0.652 (+/-0.002) for {'penalty': 'l2', 'C': 0.1}
0.670 (+/-0.004) for {'penalty': 'l1', 'C': 1.0}
0.650 (+/-0.005) for {'penalty': 'l2', 'C': 1.0}
0.670 (+/-0.004) for {'penalty': 'l1', 'C': 10.0}
0.649 (+/-0.006) for {'penalty': 'l2', 'C': 10.0}
0.669 (+/-0.004) for {'penalty': 'l1', 'C': 100.0}
0.641 (+/-0.011) for {'penalty': 'l2', 'C': 100.0}
0.669 (+/-0.004) for {'penalty': 'l1', 'C': 1000.0}
0.650 (+/-0.001) for {'penalty': 'l2', 'C': 1000.0}

